\begingroup
\setlength{\tabcolsep}{2pt}
\renewcommand{\arraystretch}{0.9}
\begin{table*}[t]
\centering
\footnotesize
\caption{競争力のある視覚言語モデルの\methodName を用いた\textbf{日本語タスク}での評価例．
``--''は評価データセットを学習に用いているためスコアが算出できないことを示す．\textbf{太字}は最も高い結果．\underline{下線}は二番目に高い結果を示している．}
\vspace{.2em}
\begin{adjustbox}{max width=\linewidth}
\begin{tabular}{lcccccccccc}
\toprule
\multirow{2}{*}{\textbf{Models}} & \textbf{CVQA} & \textbf{CC-OCR} & \textbf{JIC} & \textbf{MulIm-VQA} & \textbf{JMMMU} & \textbf{JDocQA} & \textbf{JVB-ItW} & \textbf{VG-VQA} & \textbf{Heron} & \textbf{MECHA}\\
\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(lr){4-4}\cmidrule(lr){5-5}\cmidrule(lr){6-6}\cmidrule(lr){7-7}\cmidrule(lr){8-8}\cmidrule(lr){9-9}\cmidrule(lr){10-10}\cmidrule(lr){11-11}
 & Acc. & F1 & Acc. & LLM & Acc. & LLM & LLM & LLM & LLM(%) & Acc. \\
\midrule
\multicolumn{11}{l}{\textbf{日本国内で開発されたモデル}} \\
\midrule
Llava-calm2-siglip & 6.9 & 11.4 & 58.5 & 2.9 & 6.1 & 2.2 & 3.7 & 3.6 & 57.0 & 11.3 \\
Llama-3-EvoVLM-JP-v2 & 43.8 & 10.4 & 67.0 & 3.1 & 36.4 & 2.4 & 3.5 & 3.5 & 52.0 & 50.8 \\
Asagi-14B & 19.7 & 7.5 & 76.1 & 2.2 & 21.7 & 2.1 & 3.1 & 2.2 & 46.8 & 23.8 \\
Sarashina2-Vision-8b & 48.8 & 8.2 & 78.7 & -- & 39.2 & 3.1 & 4.3 & 3.7 & 64.4 & 56.7 \\
Sarashina2-Vision-14b & 56.2 & 23.2 & 80.0 & -- & 42.6 & 3.2 & 4.3 & 3.7 & 62.4 & 64.8 \\
Heron-NVILA-Lite-1B & 29.6 & 25.5 & 47.9 & 3.2 & 26.4 & 2.3 & 3.5 & 3.5 & 57.0 & 28.9 \\
Heron-NVILA-Lite-2B & 42.4 & 29.3 & 46.4 & 3.1 & 36.9 & 2.6 & 4.0 & 3.8 & 63.2 & 48.0 \\
Heron-NVILA-Lite-15B & 60.6 & 44.5 & 80.9 & 4.3 & 49.5 & 2.9 & 4.4 & 4.1 & 69.8 & 68.3 \\
Heron-NVILA-Lite-33B & 57.6 & 51.7 & 76.8 & 4.5 & 51.1 & 3.0 & 4.4 & 4.1 & 73.4 & 68.6 \\
\midrule
\multicolumn{11}{l}{\textbf{海外で開発されたモデル}} \\
\midrule
Llava-1.5-7b & 40.9 & 14.5 & 44.0 & 2.6 & 29.6 & 2.3 & 3.0 & 3.1 & 46.0 & 38.4 \\
Llava-v1.6-mistral-7b & 27.1 & 19.9 & 70.9 & 2.4 & 27.4 & 2.0 & 3.2 & 3.1 & 29.5 & 34.0 \\
Aya-Vision-8b & 47.8 & 25.5 & 85.5 & 3.9 & 31.7 & 2.7 & 4.0 & 3.8 & 63.3 & 53.0 \\
Aya-Vision-32b & 59.6 & 35.6 & 84.6 & 4.1 & 38.7 & 2.9 & 4.1 & 3.9 & 71.5 & 67.3 \\
Pangea-7B & 48.3 & 18.7 & 85.6 & 3.4 & 37.4 & 2.5 & 3.9 & 4.1 & 59.9 & 57.3 \\
Phi-4-multimodal-instruct & 37.4 & 42.5 & 52.2 & 3.5 & 39.2 & 3.0 & 3.3 & 3.4 & 49.7 & 45.6 \\
Llama-3.2-11B-Vision-Instruct & 52.7 & 27.7 & 78.6 & 2.8 & 34.6 & 2.7 & 3.5 & 3.5 & 40.3 & 49.6 \\
Llama-3.2-90B-Vision-Instruct & 67.0 & 38.4 & -- & -- & -- & -- & -- & -- & -- & -- \\
Gemma-3-4b-it & 48.8 & 51.4 & 76.6 & 4.0 & 36.7 & 2.7 & 3.8 & 3.5 & 52.3 & 46.9 \\
Gemma-3-12b-it & 61.1 & 58.6 & 85.2 & 4.6 & 47.6 & 3.0 & 4.0 & 3.7 & 70.9 & 62.1 \\
Gemma-3-27b-it & 64.5 & 64.4 & 88.4 & 4.5 & 49.3 & 3.1 & 4.4 & 3.8 & 72.3 & 68.5 \\
InternVL3-1B & 37.4 & 60.6 & 53.1 & 2.5 & 29.5 & 2.6 & 3.3 & 3.0 & 44.4 & 37.3 \\
InternVL3-2B & 44.3 & 61.9 & 67.3 & 3.7 & 38.6 & 3.2 & 3.7 & 3.7 & 55.3 & 47.2 \\
InternVL3-8B & 54.2 & 47.8 & 80.5 & 4.4 & 49.6 & 3.4 & 4.1 & 4.0 & 70.2 & 59.8 \\
InternVL3-14B & 63.5 & 62.7 & 82.3 & 4.6 & 53.0 & 3.7 & 4.4 & 4.1 & 76.8 & 67.2 \\
InternVL3-38B & 63.0 & 67.1 & 89.4 & 4.7 & 59.0 & 3.5 & 4.4 & \underline{4.2} & \underline{81.3} & 70.4 \\
InternVL3-78B & \underline{70.0} & 50.8 & 91.2 & 4.8 & \textbf{62.8} & 3.6 & 4.4 & \textbf{4.2} & 79.7 & 74.4 \\
Qwen2-VL-7B-Instruct & 57.6 & 59.4 & 86.6 & 4.4 & 47.6 & 3.5 & 4.0 & 3.9 & 66.0 & 59.1 \\
Qwen2-VL-72B-Instruct & \textbf{72.9} & 60.5 & \textbf{92.3} & 4.7 & 59.9 & 3.8 & \underline{4.5} & 4.0 & 81.1 & \underline{75.3} \\
Qwen2.5-VL-3B-Instruct & 54.7 & 68.9 & 74.0 & 3.4 & 45.0 & 3.3 & 4.1 & 3.1 & 60.7 & 54.1 \\
Qwen2.5-VL-7B-Instruct & 56.2 & 74.8 & 82.5 & 4.2 & 47.3 & 3.7 & 4.5 & 3.9 & 69.8 & 61.4 \\
Qwen2.5-VL-32B-Instruct & 59.1 & \underline{75.4} & -- & \textbf{4.8} & 48.4 & \underline{3.8} & 4.4 & 4.0 & 75.6 & 68.5 \\
Qwen2.5-VL-72B-Instruct & \underline{70.0} & \textbf{77.3} & \underline{91.3} & \textbf{4.8} & \underline{60.5} & \textbf{3.9} & \textbf{4.6} & 4.0 & \textbf{84.5} & \textbf{76.2} \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}
\endgroup