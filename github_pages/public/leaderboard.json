[
  {
    "model": "stabilityai/japanese-instructblip-alpha",
    "url": "https://huggingface.co/stabilityai/japanese-instructblip-alpha",
    "scores": {
      "Heron": {
        "LLM": 23.53
      },
      "VG-VQA": {
        "LLM": 2.97,
        "Rouge": 34.06
      },
      "JIC": {
        "Acc": 56.63
      },
      "MECHA": {
        "Acc": 23.39
      },
      "MMMU": {
        "Acc": 25.56
      },
      "JVB-ItW": {
        "LLM": 2.26,
        "Rouge": 14.17
      },
      "LLAVA": {
        "LLM": 1.25,
        "Rouge": 0.15
      },
      "JDocQA": {
        "Acc": 12.4,
        "LLM": 2.08
      },
      "MulIm-VQA": {
        "LLM": 2.44,
        "Rouge": 25.01
      },
      "JMMMU": {
        "Acc": 26.44
      }
    }
  },
  {
    "model": "stabilityai/japanese-stable-vlm",
    "url": "https://huggingface.co/stabilityai/japanese-stable-vlm",
    "scores": {
      "Heron": {
        "LLM": 48.44
      },
      "VG-VQA": {
        "LLM": 3.47,
        "Rouge": 45.72
      },
      "JIC": {
        "Acc": 69.27
      },
      "MECHA": {
        "Acc": 4.83
      },
      "MMMU": {
        "Acc": 7.11
      },
      "JVB-ItW": {
        "LLM": 3.28,
        "Rouge": 23.17
      },
      "LLAVA": {
        "LLM": 1.4,
        "Rouge": 0.58
      },
      "JDocQA": {
        "Acc": 13.09,
        "LLM": 2.09
      },
      "MulIm-VQA": {
        "LLM": 2.33,
        "Rouge": 40.7
      },
      "JMMMU": {
        "Acc": 3.41
      }
    }
  },
  {
    "model": "SakanaAI/Llama-3-EvoVLM-JP-v2",
    "url": "https://huggingface.co/SakanaAI/Llama-3-EvoVLM-JP-v2",
    "scores": {
      "Heron": {
        "LLM": 47.59
      },
      "VG-VQA": {
        "LLM": 3.43,
        "Rouge": 24.67
      },
      "JIC": {
        "Acc": 67.05
      },
      "MECHA": {
        "Acc": 50.74
      },
      "MMMU": {
        "Acc": 38.89
      },
      "JVB-ItW": {
        "LLM": 3.48,
        "Rouge": 48.38
      },
      "LLAVA": {
        "LLM": 2.87,
        "Rouge": 27.88
      },
      "JDocQA": {
        "Acc": 15.45,
        "LLM": 2.35
      },
      "MulIm-VQA": {
        "LLM": 3.13,
        "Rouge": 44.31
      },
      "JMMMU": {
        "Acc": 36.36
      }
    }
  },
  {
    "model": "cyberagent/llava-calm2-siglip",
    "url": "https://huggingface.co/cyberagent/llava-calm2-siglip",
    "scores": {
      "Heron": {
        "LLM": 54.1
      },
      "VG-VQA": {
        "LLM": 3.57,
        "Rouge": 17.7
      },
      "JIC": {
        "Acc": 58.48
      },
      "MECHA": {
        "Acc": 11.2
      },
      "MMMU": {
        "Acc": 26.67
      },
      "JVB-ItW": {
        "LLM": 3.66,
        "Rouge": 46.27
      },
      "LLAVA": {
        "LLM": 1.95,
        "Rouge": 2.92
      },
      "JDocQA": {
        "Acc": 8.15,
        "LLM": 2.05
      },
      "MulIm-VQA": {
        "LLM": 2.75,
        "Rouge": 40.63
      },
      "JMMMU": {
        "Acc": 6.14
      }
    }
  },
  {
    "model": "llm-jp/llm-jp-3-vila-14b",
    "url": "https://huggingface.co/llm-jp/llm-jp-3-vila-14b",
    "scores": {
      "Heron": {
        "LLM": 68.03
      },
      "VG-VQA": {
        "LLM": 3.93,
        "Rouge": 16.21
      },
      "JIC": {
        "Acc": 81.35
      },
      "MECHA": {
        "Acc": 45.63
      },
      "MMMU": {
        "Acc": 32.67
      },
      "JVB-ItW": {
        "LLM": 4.08,
        "Rouge": 52.38
      },
      "LLAVA": {
        "LLM": 3.35,
        "Rouge": 36.04
      },
      "JDocQA": {
        "Acc": 17.34,
        "LLM": 2.51
      },
      "MulIm-VQA": {
        "LLM": 3.51,
        "Rouge": 46.96
      },
      "JMMMU": {
        "Acc": 19.02
      }
    }
  },
  {
    "model": "sbintuitions/sarashina2-vision-8b",
    "url": "https://huggingface.co/sbintuitions/sarashina2-vision-8b",
    "scores": {
      "Heron": {
        "LLM": 60.45
      },
      "VG-VQA": {
        "LLM": 3.72,
        "Rouge": 25.45
      },
      "JIC": {
        "Acc": 78.68
      },
      "MECHA": {
        "Acc": 56.29
      },
      "MMMU": {
        "Acc": 29.67
      },
      "JVB-ItW": {
        "LLM": 4.06,
        "Rouge": 44.8
      },
      "LLAVA": {
        "LLM": 2.45,
        "Rouge": 16.94
      },
      "JDocQA": {
        "Acc": 22.61,
        "LLM": 2.98
      },
      "MulIm-VQA": {
        "LLM": 2.62,
        "Rouge": 30.2
      },
      "JMMMU": {
        "Acc": 39.17
      }
    }
  },
  {
    "model": "sbintuitions/sarashina2-vision-14b",
    "url": "https://huggingface.co/sbintuitions/sarashina2-vision-14b",
    "scores": {
      "Heron": {
        "LLM": 60.15
      },
      "VG-VQA": {
        "LLM": 3.72,
        "Rouge": 25.34
      },
      "JIC": {
        "Acc": 80.03
      },
      "MECHA": {
        "Acc": 64.42
      },
      "MMMU": {
        "Acc": 33.78
      },
      "JVB-ItW": {
        "LLM": 4.04,
        "Rouge": 44.3
      },
      "LLAVA": {
        "LLM": 2.52,
        "Rouge": 15.59
      },
      "JDocQA": {
        "Acc": 23.94,
        "LLM": 3.07
      },
      "MulIm-VQA": {
        "LLM": 2.64,
        "Rouge": 35.3
      },
      "JMMMU": {
        "Acc": 42.95
      }
    }
  },
  {
    "model": "MIL-UT/Asagi-14B",
    "url": "https://huggingface.co/MIL-UT/Asagi-14B",
    "scores": {
      "Heron": {
        "LLM": 41.85
      },
      "VG-VQA": {
        "LLM": 1.96,
        "Rouge": 9.29
      },
      "JIC": {
        "Acc": 76.2
      },
      "MECHA": {
        "Acc": 24.05
      },
      "MMMU": {
        "Acc": 15.33
      },
      "JVB-ItW": {
        "LLM": 2.9,
        "Rouge": 30.88
      },
      "LLAVA": {
        "LLM": 1.57,
        "Rouge": 0.05
      },
      "JDocQA": {
        "Acc": 10.38,
        "LLM": 1.99
      },
      "MulIm-VQA": {
        "LLM": 2.0,
        "Rouge": 18.39
      },
      "JMMMU": {
        "Acc": 21.74
      }
    }
  },
  {
    "model": "llava-hf/llava-1.5-7b-hf",
    "url": "https://huggingface.co/llava-hf/llava-1.5-7b-hf",
    "scores": {
      "Heron": {
        "LLM": 43.14
      },
      "VG-VQA": {
        "LLM": 2.98,
        "Rouge": 13.97
      },
      "JIC": {
        "Acc": 43.99
      },
      "MECHA": {
        "Acc": 38.17
      },
      "MMMU": {
        "Acc": 34.0
      },
      "JVB-ItW": {
        "LLM": 3.02,
        "Rouge": 40.75
      },
      "LLAVA": {
        "LLM": 2.93,
        "Rouge": 34.55
      },
      "JDocQA": {
        "Acc": 14.79,
        "LLM": 2.17
      },
      "MulIm-VQA": {
        "LLM": 2.55,
        "Rouge": 35.78
      },
      "JMMMU": {
        "Acc": 29.62
      }
    }
  },
  {
    "model": "llava-hf/llava-v1.6-mistral-7b-hf",
    "url": "https://huggingface.co/llava-hf/llava-v1.6-mistral-7b-hf",
    "scores": {
      "Heron": {
        "LLM": 30.04
      },
      "VG-VQA": {
        "LLM": 3.05,
        "Rouge": 11.71
      },
      "JIC": {
        "Acc": 58.22
      },
      "MECHA": {
        "Acc": 34.43
      },
      "MMMU": {
        "Acc": 35.89
      },
      "JVB-ItW": {
        "LLM": 2.92,
        "Rouge": 28.62
      },
      "LLAVA": {
        "LLM": 3.25,
        "Rouge": 30.72
      },
      "JDocQA": {
        "Acc": 14.38,
        "LLM": 1.98
      },
      "MulIm-VQA": {
        "LLM": 2.31,
        "Rouge": 25.22
      },
      "JMMMU": {
        "Acc": 25.45
      }
    }
  },
  {
    "model": "neulab/Pangea-7B-hf",
    "url": "https://huggingface.co/neulab/Pangea-7B-hf",
    "scores": {
      "Heron": {
        "LLM": 56.97
      },
      "VG-VQA": {
        "LLM": 4.13,
        "Rouge": 54.19
      },
      "JIC": {
        "Acc": 85.57
      },
      "MECHA": {
        "Acc": 56.51
      },
      "MMMU": {
        "Acc": 43.67
      },
      "JVB-ItW": {
        "LLM": 3.86,
        "Rouge": 33.54
      },
      "LLAVA": {
        "LLM": 3.52,
        "Rouge": 25.94
      },
      "JDocQA": {
        "Acc": 16.17,
        "LLM": 2.36
      },
      "MulIm-VQA": {
        "LLM": 3.38,
        "Rouge": 40.27
      },
      "JMMMU": {
        "Acc": 37.42
      }
    }
  },
  {
    "model": "mistralai/Pixtral-12B-2409",
    "url": "https://huggingface.co/mistralai/Pixtral-12B-2409",
    "scores": {
      "Heron": {
        "LLM": 60.88
      },
      "VG-VQA": {
        "LLM": 3.52,
        "Rouge": 13.08
      },
      "JIC": {
        "Acc": 61.07
      },
      "MECHA": {
        "Acc": 56.4
      },
      "MMMU": {
        "Acc": 48.56
      },
      "JVB-ItW": {
        "LLM": 3.9,
        "Rouge": 38.29
      },
      "LLAVA": {
        "LLM": 3.63,
        "Rouge": 31.56
      },
      "JDocQA": {
        "Acc": 14.77,
        "LLM": 2.44
      },
      "MulIm-VQA": {
        "LLM": 4.11,
        "Rouge": 34.48
      },
      "JMMMU": {
        "Acc": 18.71
      }
    }
  },
  {
    "model": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "url": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "scores": {
      "Heron": {
        "LLM": 38.08
      },
      "VG-VQA": {
        "LLM": 3.32,
        "Rouge": 14.23
      },
      "JIC": {
        "Acc": 78.71
      },
      "MECHA": {
        "Acc": 49.31
      },
      "MMMU": {
        "Acc": 38.22
      },
      "JVB-ItW": {
        "LLM": 3.36,
        "Rouge": 30.43
      },
      "LLAVA": {
        "LLM": 3.7,
        "Rouge": 30.2
      },
      "JDocQA": {
        "Acc": 17.61,
        "LLM": 2.52
      },
      "MulIm-VQA": {
        "LLM": 2.64,
        "Rouge": 24.5
      },
      "JMMMU": {
        "Acc": 34.62
      }
    }
  },
  {
    "model": "Efficient-Large-Model/VILA1.5-13b",
    "url": "https://huggingface.co/Efficient-Large-Model/VILA1.5-13b",
    "scores": {
      "Heron": {
        "LLM": 46.93
      },
      "VG-VQA": {
        "LLM": 3.23,
        "Rouge": 12.97
      },
      "JIC": {
        "Acc": 58.2
      },
      "MECHA": {
        "Acc": 46.35
      },
      "MMMU": {
        "Acc": 37.0
      },
      "JVB-ItW": {
        "LLM": 3.48,
        "Rouge": 42.49
      },
      "LLAVA": {
        "LLM": 3.6,
        "Rouge": 34.96
      },
      "JDocQA": {
        "Acc": 14.82,
        "LLM": 2.22
      },
      "MulIm-VQA": {
        "LLM": 3.16,
        "Rouge": 40.01
      },
      "JMMMU": {
        "Acc": 33.48
      }
    }
  },
  {
    "model": "OpenGVLab/InternVL2-8B",
    "url": "https://huggingface.co/OpenGVLab/InternVL2-8B",
    "scores": {
      "Heron": {
        "LLM": 49.82
      },
      "VG-VQA": {
        "LLM": 3.48,
        "Rouge": 11.66
      },
      "JIC": {
        "Acc": 65.73
      },
      "MECHA": {
        "Acc": 50.52
      },
      "MMMU": {
        "Acc": 49.67
      },
      "JVB-ItW": {
        "LLM": 3.52,
        "Rouge": 33.79
      },
      "LLAVA": {
        "LLM": 3.07,
        "Rouge": 31.47
      },
      "JDocQA": {
        "Acc": 19.79,
        "LLM": 2.7
      },
      "MulIm-VQA": {
        "LLM": 2.89,
        "Rouge": 34.48
      },
      "JMMMU": {
        "Acc": 39.09
      }
    }
  },
  {
    "model": "OpenGVLab/InternVL2-26B",
    "url": "https://huggingface.co/OpenGVLab/InternVL2-26B",
    "scores": {
      "Heron": {
        "LLM": 59.69
      },
      "VG-VQA": {
        "LLM": 3.65,
        "Rouge": 11.58
      },
      "JIC": {
        "Acc": 73.92
      },
      "MECHA": {
        "Acc": 51.29
      },
      "MMMU": {
        "Acc": 48.22
      },
      "JVB-ItW": {
        "LLM": 3.08,
        "Rouge": 26.74
      },
      "LLAVA": {
        "LLM": 3.75,
        "Rouge": 30.55
      },
      "JDocQA": {
        "Acc": 15.28,
        "LLM": 2.6
      },
      "MulIm-VQA": {
        "LLM": 3.31,
        "Rouge": 45.4
      },
      "JMMMU": {
        "Acc": 39.02
      }
    }
  },
  {
    "model": "Qwen/Qwen2.5-VL-7B-Instruct",
    "url": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "scores": {
      "Heron": {
        "LLM": 70.29
      },
      "VG-VQA": {
        "LLM": 3.69,
        "Rouge": 8.99
      },
      "JIC": {
        "Acc": 82.66
      },
      "MECHA": {
        "Acc": 60.02
      },
      "MMMU": {
        "Acc": 50.0
      },
      "JVB-ItW": {
        "LLM": 4.28,
        "Rouge": 29.63
      },
      "LLAVA": {
        "LLM": 3.93,
        "Rouge": 27.13
      },
      "JDocQA": {
        "Acc": 26.47,
        "LLM": 3.59
      },
      "MulIm-VQA": {
        "LLM": 4.11,
        "Rouge": 50.37
      },
      "JMMMU": {
        "Acc": 48.18
      }
    }
  },
  {
    "model": "Qwen/Qwen2.5-VL-32B-Instruct",
    "url": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "scores": {
      "Heron": {
        "LLM": 74.8
      },
      "VG-VQA": {
        "LLM": 3.76,
        "Rouge": 5.22
      },
      "JIC": {
        "Acc": 96.01
      },
      "MECHA": {
        "Acc": 68.37
      },
      "MMMU": {
        "Acc": 59.11
      },
      "JVB-ItW": {
        "LLM": 4.3,
        "Rouge": 14.67
      },
      "LLAVA": {
        "LLM": 4.0,
        "Rouge": 18.95
      },
      "JDocQA": {
        "Acc": 25.21,
        "LLM": 3.8
      },
      "MulIm-VQA": {
        "LLM": 4.64,
        "Rouge": 42.21
      },
      "JMMMU": {
        "Acc": 48.79
      }
    }
  },
  {
    "model": "Qwen/Qwen2.5-VL-72B-Instruct",
    "url": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "scores": {
      "Heron": {
        "LLM": 85.46
      },
      "VG-VQA": {
        "LLM": 3.89,
        "Rouge": 9.83
      },
      "JIC": {
        "Acc": 90.36
      },
      "MECHA": {
        "Acc": 74.68
      },
      "MMMU": {
        "Acc": 63.0
      },
      "JVB-ItW": {
        "LLM": 4.4,
        "Rouge": 32.04
      },
      "LLAVA": {
        "LLM": 4.05,
        "Rouge": 28.67
      },
      "JDocQA": {
        "Acc": 23.92,
        "LLM": 3.89
      },
      "MulIm-VQA": {
        "LLM": 4.8,
        "Rouge": 60.86
      },
      "JMMMU": {
        "Acc": 60.61
      }
    }
  },
  {
    "model": "google/gemma-3-4b-it",
    "url": "https://huggingface.co/google/gemma-3-4b-it",
    "scores": {
      "Heron": {
        "LLM": 52.83
      },
      "VG-VQA": {
        "LLM": 3.43,
        "Rouge": 12.46
      },
      "JIC": {
        "Acc": 75.36
      },
      "MECHA": {
        "Acc": 47.17
      },
      "MMMU": {
        "Acc": 40.67
      },
      "JVB-ItW": {
        "LLM": 3.68,
        "Rouge": 37.14
      },
      "LLAVA": {
        "LLM": 3.57,
        "Rouge": 22.13
      },
      "JDocQA": {
        "Acc": 17.55,
        "LLM": 2.59
      },
      "MulIm-VQA": {
        "LLM": 3.71,
        "Rouge": 52.69
      },
      "JMMMU": {
        "Acc": 36.97
      }
    }
  },
  {
    "model": "google/gemma-3-12b-it",
    "url": "https://huggingface.co/google/gemma-3-12b-it",
    "scores": {
      "Heron": {
        "LLM": 72.19
      },
      "VG-VQA": {
        "LLM": 3.74,
        "Rouge": 12.49
      },
      "JIC": {
        "Acc": 85.72
      },
      "MECHA": {
        "Acc": 62.6
      },
      "MMMU": {
        "Acc": 48.11
      },
      "JVB-ItW": {
        "LLM": 4.3,
        "Rouge": 35.68
      },
      "LLAVA": {
        "LLM": 4.02,
        "Rouge": 22.11
      },
      "JDocQA": {
        "Acc": 20.13,
        "LLM": 2.98
      },
      "MulIm-VQA": {
        "LLM": 4.22,
        "Rouge": 59.66
      },
      "JMMMU": {
        "Acc": 47.58
      }
    }
  },
  {
    "model": "google/gemma-3-27b-it",
    "url": "https://huggingface.co/google/gemma-3-27b-it",
    "scores": {
      "Heron": {
        "LLM": 69.15
      },
      "VG-VQA": {
        "LLM": 3.75,
        "Rouge": 10.91
      },
      "JIC": {
        "Acc": 88.23
      },
      "MECHA": {
        "Acc": 67.66
      },
      "MMMU": {
        "Acc": 56.11
      },
      "JVB-ItW": {
        "LLM": 4.36,
        "Rouge": 30.89
      },
      "LLAVA": {
        "LLM": 3.93,
        "Rouge": 21.07
      },
      "JDocQA": {
        "Acc": 20.17,
        "LLM": 3.1
      },
      "MulIm-VQA": {
        "LLM": 4.33,
        "Rouge": 56.29
      },
      "JMMMU": {
        "Acc": 50.53
      }
    }
  },
  {
    "model": "microsoft/Phi-4-multimodal-instruct",
    "url": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "scores": {
      "Heron": {
        "LLM": 45.52
      },
      "VG-VQA": {
        "LLM": 3.3,
        "Rouge": 19.0
      },
      "JIC": {
        "Acc": 52.27
      },
      "MECHA": {
        "Acc": 46.35
      },
      "MMMU": {
        "Acc": 53.67
      },
      "JVB-ItW": {
        "LLM": 3.2,
        "Rouge": 26.8
      },
      "LLAVA": {
        "LLM": 3.37,
        "Rouge": 29.48
      },
      "JDocQA": {
        "Acc": 22.85,
        "LLM": 2.9
      },
      "MulIm-VQA": {
        "LLM": 3.38,
        "Rouge": 42.34
      },
      "JMMMU": {
        "Acc": 39.17
      }
    }
  },
  {
    "model": "gpt-4o-2024-11-20",
    "url": "https://huggingface.co/gpt-4o-2024-11-20",
    "scores": {
      "Heron": {
        "LLM": 93.7
      },
      "VG-VQA": {
        "LLM": 3.93,
        "Rouge": 11.77
      },
      "JIC": {
        "Acc": 95.77
      },
      "MECHA": {
        "Acc": 83.69
      },
      "MMMU": {
        "Acc": 56.11
      },
      "JVB-ItW": {
        "LLM": 4.44,
        "Rouge": 32.2
      },
      "LLAVA": {
        "LLM": 4.13,
        "Rouge": 29.77
      },
      "JDocQA": {
        "Acc": 22.0,
        "LLM": 3.59
      },
      "MulIm-VQA": {
        "LLM": 4.75,
        "Rouge": 62.51
      },
      "JMMMU": {
        "Acc": 57.5
      }
    }
  }
]